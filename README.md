# Hippo
Mesos framework for eating tasks off queues and running them as docker containers.  One-off tasks are also supported.

The two abstractions used are "Queues" and "Tasks".  Queues are definitions for things that generate tasks, and tasks are
the records for the actual mesos tasks that were triggered.  One-off tasks can also be generated outside of a queue.


## API

**Queues**

```javascript
{
    // Unique ID for the queue, generated by Hippo during creation
    "id": "1111-11111-1111-1111",
    // Container definition follows normal marathon formatting and is required.
    // Each task will create a container with these settings.
    "container": {
        "docker": {
            "image" : "myrepo/myimage:mytag",
            // network is optional, defaults to bridge
            "network": "BRIDGE"
        },
        // Volumes work just like marathon volume definitions, optional
        "volumes": [
            {
                "hostPath":"/some/host/path",
                "containerPath":"/some/container/path",
                "mode":"RW"
            }
        ]
    },
    // Mesos memory setting, required
    "mem": 32,
    // Mesos cpu setting, required
    "cpus": 0.1,
    // Command to run, required
    "cmd": "mycommand --with --my --args"
    // Marathon formatted ENV vars to pass to container, optional
    "env": {
        "MYVARNAME":"MYVARVALUE"
    },
    // Marathon formatted contraints, optional
    "constraints": [
        ["rack","EQUAL","rack1"]
    ],
    // Number of retries if mesos result is TASK_FAILED, defaults to 0, optional
    "task_retries": 0,
    // Number of retries if task fails to run but it's the systems fault, defaults to 2, optional
    "system_retries": 2,
    // Definition for the queue data source
    "queue": {
        // The type of the queue, see Queue Types documentation for possibilites
        "type": "sqs",
        // Label for this queue definition, info only
        "name": "myQueueName",
        // Number of tasks that can be processed concurrently for this queue, defaults to 10000, optional
        "max_concurrent": 10,
        // Number of tasks to group if more than one task is created from the data source at once, defaults to 1
        "batch_size": 1,
        // Character used to join multiple tasks strings into one batch string
        "batch_separator": "|",
        // Number of seconds between polls of the data source, defaults to 60
        "frequency_seconds": 60,
        // Unix timestamp for last time the data source was polled, not needed on creation
        "last_run_tstamp": 0,
        // Status of the queue, can be "ENABLED" or "DISABLED
        "status": "ENABLED",
        // Settings for the specific queue type, will vary
        "sqs": {
            "awskey":"someKey",
            "awssecret":"someSecret",
            "awsregion":"someRegion",
            "queuename":"someSqsQueueName"
        }
    }
}
```

`/queues/`

- GET, POST, PUT
- List existing queues, or create a new queue

`/queues/:queueId/`

- GET, POST, PUT, DELETE
- CRUD for a single queue

`/queues/:queueId/toggle/`

- GET
- Enables/Disables a queue


`/queuetypes/`

- GET
- Returns list of queue types enabled on this hippo server

**Tasks**

```javascript
{
    // Unique ID for the task family, generated by Hippo during creation if not provided
    "id": "myId",
    // Id created for the mesos task, generated by the system
    "mesos_id": "myId.11111-11111-11111-11111",
    // Container definition follows normal marathon formatting and is required.
    // Each task will create a container with these settings.
    "container": {
        "docker": {
            "image" : "myrepo/myimage:mytag",
            // network is optional, defaults to bridge
            "network": "BRIDGE"
        },
        // Volumes work just like marathon volume definitions, optional
        "volumes": [
            {
                "hostPath":"/some/host/path",
                "containerPath":"/some/container/path",
                "mode":"RW"
            }
        ]
    },
    // Mesos memory setting, required
    "mem": 32,
    // Mesos cpu setting, required
    "cpus": 0.1,
    // Command to run, required
    "cmd": "mycommand --with --my --args"
    // Marathon formatted ENV vars to pass to container, optional
    "env": {
        "MYVARNAME":"MYVARVALUE"
    },
    // Marathon formatted contraints, optional
    "constraints": [
        ["rack","EQUAL","rack1"]
    ],
    // Number of retries if mesos result is TASK_FAILED, defaults to 0, optional
    "task_retries": 0,
    // Number of retries if task fails to run but it's the systems fault, defaults to 2, optional
    "system_retries": 2,
    // Number of tasks that can be processed concurrently for tasks with the same ID, defaults to 10, optional
    "max_concurrent": 10
}
```

`/tasks/`

- GET, POST
- List recent tasks, or create a new one-off task

`/tasks/:taskId/`

- GET, DELETE
- Get info on a task, or delete that task record

`/tasks/:taskId/kill/`

- GET, POST
- Kill a running task


## Queue Types

- AWS SQS
  - namespace: sqs
  - parameters:
    - awskey
    - awssecret
    - awsregion
    - queuename
- AWS S3
  - namespace: s3bucket
  - parameters:
    - awskey
    - awssecret
    - awsregion
    - bucket_name
    - earliest_unix_tstamp
- Redis Queue
  - namespace: redis
  - parameters:
    - host
    - port
    - db
    - name
- SQL Query
  - namespace: sqlquery
  - parameters:
    - conn_string
    - query
    - filter_field
    - filter_val
- Cron String
  - namespace: cron
  - parameters:
    - cronstring
    - maxbacklog

## Architecture

Hippo UI/API -> redis <- Hippo Workers <--> Mesos
                                     \
                                      -> Queue Data Sources
